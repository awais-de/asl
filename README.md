# ğŸ–ï¸ English-to-Sign Language (ASL) Translation System  
*A Semester-Long NLP + Computer Vision Project*

---

## ğŸ“œ Overview  
This project implements a **multi-stage training and evaluation pipeline** for translating English sentences into **American Sign Language (ASL)** gloss and mapping them to corresponding sign videos.

Unlike basic rule-based approaches, this system integrates:  
- **Natural Language Processing (NLP)** for accurate English â†’ ASL gloss translation.  
- **Dataset preprocessing and tokenization** for machine learning training.  
- **Text-to-gloss model training & evaluation** using PyTorch + Hugging Face.  
- **Optional video mapping** via the WLASL2000 dataset.  

You can run everything either via:  
- ğŸ““ **`notebooks/TextToSignLanguage.ipynb`** (end-to-end workflow in a single notebook).  
- ğŸ–¥ï¸ **Python scripts in `src/`** (modular execution).  

---

## ğŸ¯ Project Goals  
1. **Translate** natural English text into **ASL gloss**.  
2. **Align gloss tokens** with real-world ASL sign videos.  
3. **Train & evaluate** a text-to-gloss translation model.  
4. **Enable future integration** with video rendering or sign language avatars.

---

## ğŸ“‚ Directory Structure  
asl_project/
â”œâ”€â”€ data/ # Dataset storage and processing outputs
â”‚ â”œâ”€â”€ raw/ # Original datasets (ASLG_PC12, WLASL2000)
â”‚ â”œâ”€â”€ processed/ # Cleaned, tokenized datasets & mappings
â”‚ â””â”€â”€ poses/ # (Optional) Pose keypoints from sign videos
â”‚
â”œâ”€â”€ src/ # Source code (modular scripts)
â”‚ â”œâ”€â”€ data_loading/
â”‚ â”‚ â”œâ”€â”€ load_videos_dataset.py
â”‚ â”‚ â””â”€â”€ prepare_dataloader.py
â”‚ â”œâ”€â”€ preprocessing/
â”‚ â”‚ â”œâ”€â”€ data_preprocessing.py
â”‚ â”‚ â””â”€â”€ tokenize_aslg_pc12.py
â”‚ â”œâ”€â”€ verification/
â”‚ â”‚ â””â”€â”€ check_dataset_and_model.py
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ train.py
â”‚ â”‚ â””â”€â”€ evaluate.py
â”‚ â””â”€â”€ app.py
â”‚
â”œâ”€â”€ notebooks/ # Prototyping & experiments
â”‚ â””â”€â”€ TextToSignLanguage.ipynb # Main notebook
â”‚
â”œâ”€â”€ logs/ # Training and run logs
â”œâ”€â”€ models/ # Saved checkpoints & trained models
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md # This file


---

## ğŸ”„ Pipeline Overview  

The workflow can be followed either inside the **notebook** or step-by-step via **scripts**:

| **Step** | **Notebook Section / Script** | **Description** |
|----------|-------------------------------|-----------------|
| **0. Config Setup** | Notebook: *Setup & Imports* | Initialize paths, configs, and dependencies |
| **1. Load Datasets** | `src/data_loading/load_videos_dataset.py` | Download ASLG_PC12 & WLASL2000 |
| **2. Preprocess Datasets** | Notebook: *Data Preprocessing* / `src/preprocessing/data_preprocessing.py` | Clean datasets, build gloss-to-video mapping |
| **3. Tokenization** | Notebook: *Tokenization* / `src/preprocessing/tokenize_aslg_pc12.py` | Tokenize dataset for training |
| **4. DataLoader Prep** | Notebook: *DataLoader* / `src/data_loading/prepare_dataloader.py` | Build PyTorch DataLoaders |
| **5. Verification** | Notebook: *Sanity Checks* / `src/verification/check_dataset_and_model.py` | Validate setup |
| **6. Training** | Notebook: *Model Training* / `src/models/train.py` | Train text-to-gloss translation model |
| **7. Evaluation** | Notebook: *Evaluation* / `src/models/evaluate.py` | Generate predictions and evaluate model |
| **8. Gloss-to-Video Mapping** | Notebook: *Video Retrieval* | Map predicted gloss tokens to videos and stitch into final output |

---

## ğŸ“Š Datasets Used  
- **ASLG_PC12** â€” English â†” ASL gloss parallel dataset.  
- **WLASL2000** â€” Gloss-to-video mapping dataset.  

*(Future integration planned for How2Sign, SignBank, etc.)*

---

## ğŸš€ Usage
1. Run LoadAndTrainDataset.ipynb
2. Run TextToSignLanguage.ipynb
