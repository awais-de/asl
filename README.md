# ğŸ–ï¸ English-to-Sign Language (ASL) Translation System  
*A Semester-Long NLP + Computer Vision Project*

## ğŸ“œ Overview  
This project implements a **complex, multi-stage pipeline** that translates English sentences into **American Sign Language (ASL)**, then renders the translation as **sign videos** or **3D avatar animations**.

Unlike simple rule-based or one-step implementations, this system integrates:  
- **Natural Language Processing (NLP)** for grammar-aware English â†’ ASL gloss translation.  
- **Computer Vision (CV)** for sign video retrieval and pose-based rendering.  
- **Dataset fusion** from multiple large-scale ASL datasets.

## ğŸ¯ Project Goals  
1. **Translate** natural English text into **ASL gloss** (a written representation of sign language).  
2. **Align gloss tokens** with real-world ASL sign videos or pose sequences.  
3. **Render** an animated or video-based output for end-users.  
4. **Enable scalability** for more sign languages and larger vocabularies.

## ğŸ“‚ Directory Structure  
asl_project/
â”œâ”€â”€ data/ # Datasets and preprocessing outputs
â”‚ â”œâ”€â”€ raw/ # Original datasets (ASLG-PC12, WLASL2000, How2Sign)
â”‚ â”œâ”€â”€ processed/ # Processed / preprocessed dataset files & mappings
â”‚ â””â”€â”€ poses/ # Extracted pose keypoints from sign videos
â”‚
â”œâ”€â”€ src/ # Source code
â”‚ â”œâ”€â”€ data_loading/ # Scripts to download and load datasets
â”‚ â”‚ â””â”€â”€ load_videos_dataset.py
â”‚ â”œâ”€â”€ preprocessing/ # Dataset cleaning, tokenization, alignment
â”‚ â”‚ â””â”€â”€ preprocess_videos.py
â”‚ â”œâ”€â”€ text_to_gloss/ # Text-to-gloss model and related scripts
â”‚ â”‚ â””â”€â”€ text_to_gloss_model.py
â”‚ â”œâ”€â”€ retrieval/ # Sign video retrieval / pose matching scripts
â”‚ â”œâ”€â”€ rendering/ # Video player or avatar rendering code
â”‚ â”œâ”€â”€ evaluation/ # Model evaluation metrics
â”‚ â”œâ”€â”€ utils/ # Utility scripts for normalization, mapping, IO
â”‚ â””â”€â”€ app.py # CLI or web app interface
â”‚
â”œâ”€â”€ notebooks/ # Jupyter notebooks for prototyping and experiments
â”‚
â”œâ”€â”€ logs/ # Logs for training and experiments
â”œâ”€â”€ models/ # Saved ML models and checkpoints
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # This file

## ğŸ”„ Pipeline Overview  
1. **Data Preparation**: Download & preprocess ASLG-PC12, How2Sign, WLASL datasets using scripts in `src/data_loading/` and `src/preprocessing/`.  
2. **NLP Model**: Fine-tune transformer (T5/mBART) for English â†’ ASL gloss inside `src/text_to_gloss/`.  
3. **Gloss Mapping**: Map gloss tokens to sign videos or generate fingerspelling.  
4. **Pose Rendering**: Render 3D avatar or 2D pose keypoints.  
5. **Output**: Play sign video sequence or avatar animation.

## ğŸ“Š Datasets  
- ASLG-PC12  
- WLASL2000  
- How2Sign  
- SignBank

## ğŸ’» Installation  
```bash
git clone https://github.com/yourusername/asl_project.git
cd asl_project
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
